sum(z==Negative) # 2898 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
Tags.Train <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
sum(z==Positive)
z <- c(SMS.Data$Tag[train.Range])
sum(z==Positive)
sum(z==Negative)
train.Range
z
sum(z=="spam")
sum(z=="ham")
z <- c(SMS.Data$Tag[train.Range])
sum(z==Positive) # 88 - Number of Positive events ("spam") in the Test Data
sum(z==Negative) # 512 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
Tags.Train <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
test.Range
z <- c(SMS.Data$Tag[test.Range]);
sum(z==Positive) # 381 - Number of Positive events ("spam") in the Test Data
sum(z==Negative)
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
Tags.Test <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
set.seed(0)
prob.test <- knn(train.doc, test.doc, Tags.Train, k = 2, prob=TRUE) # k-number of neighbors considered
# Display Classification Results
a <- 1:length(prob.test)
b <- levels(prob.test)[prob.test] # asign your classification Tags (Talk or Sci)
c <- attributes(prob.test)$prob # asign your classification probability values
d <- prob.test==Tags.Test # Logicaly match your classification Tags with the known "Tags"
result <- data.frame(Doc=a,Predict=b,Prob=c, Correct=d) # Tabulate your result
sum(d)/length(Tags.Test) # % Correct Classification (0.86)
# KNN Classification of SMS Dataset
rm(list=ls()); cat("\014") # clear all
library(tm) # Use this package for Text Mining
load("Data/SMS_DTM.RData") # Load dtm from saved data
dtm <- as.matrix(dtm)
dtm <- dtm[1:1000,] # Subset DTM
# Split the Document-Term Matrix into Train & Test Datasets
library(class) #
# Consider "spam" as Positive and "ham" as Negative
Positive <- "spam"; Negative <- "ham"; CM.Names <- c(Positive,Negative)
DS.Size <- dim(dtm)[1]
Test.Train.Percent <- 0.6 # Split Data into 60% for Training and 40% for Testing
ix.Range <- round(DS.Size*Test.Train.Percent)
train.Range <- seq(from = 1, to = ix.Range, by = 1); test.Range <- seq(from = (ix.Range+1), to = DS.Size, by = 1)
train.doc <- dtm[train.Range,] # Dataset for which classification is already known
test.doc <- dtm[test.Range,] # Dataset we are trying to classify
# Generate TAGS - Correct answers for the Train dataset
z <- c(SMS.Data$Tag[train.Range])
sum(z==Positive) # 88 - Number of Positive events ("spam") in the Test Data
sum(z==Negative) # 512 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
Tags.Train <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
# Generate TAGS - Correct answers for the Test dataset
z <- c(SMS.Data$Tag[test.Range]);
sum(z==Positive) # 64 - Number of Positive events ("spam") in the Test Data
sum(z==Negative) # 336 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
Tags.Test <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
# 1) KNN Classificationusing package "class" ====
set.seed(0)
prob.test <- knn(train.doc, test.doc, Tags.Train, k = 2, prob=TRUE) # k-number of neighbors considered
### -----------
# Display Classification Results
a <- 1:length(prob.test)
b <- levels(prob.test)[prob.test] # asign your classification Tags (Talk or Sci)
c <- attributes(prob.test)$prob # asign your classification probability values
d <- prob.test==Tags.Test # Logicaly match your classification Tags with the known "Tags"
result <- data.frame(Doc=a,Predict=b,Prob=c, Correct=d) # Tabulate your result
sum(d)/length(Tags.Test) # % Correct Classification (0.86)
# Insert your code to find:
# Confusion Matrix
table(prob.test, Tags) #auto generated
sum(d)/length(Tags.Test) # % Correct Classification (0.86)
Tags.Test
Tags.Train
# Insert your code to find:
# Confusion Matrix
table(prob.test, CM.Names) #auto generated
# Insert your code to find:
# Confusion Matrix
table(prob.test) #auto generated
# Insert your code to find:
# Confusion Matrix
table(prob.test, Tags.Train) #auto generated
prob.test
Tags.Train
# Insert your code to find:
# Confusion Matrix
table(prob.test, Tags.Test) #auto generated
prob.test
Tags.Train
train.Range
test.Range
sum(z==Positive)
# Generate TAGS - Correct answers for the Test dataset
z <- c(SMS.Data$Tag[test.Range]);
sum(z==Positive) # 64 - Number of Positive events ("spam") in the Test Data
sum(z==Negative) # 336 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
z
Tags.Test <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
Tags.Test
# Insert your code to find:
# Confusion Matrix
table(prob.test, Tags.Test) #auto generated
spam.classified <- (prob.test == Tags.Test)
ham.classified <- (prob.test == Tags.Test)
spam.classified
ham.classified
TP <- sum(spam.classified == TRUE)
FP <- sum(spam.classified == FALSE)
TN <- sum(ham.classified == TRUE)
FN <- sum(ham.classified == FALSE)
confusion.matrix <- data.frame(Spam = c(TP, FN), Ham = c(FP, TN), row.names = c("Spam", "Ham"))
confusion.matrix
#precision
precision <- TP/(TP + FP)
precision
#recall
recall <- TP/(TP + FN)
recall
#F score
f.score <- 2*((precision * recall)/(precision + recall))
f.score
(TP+TN)/(TP+TN+FP+FN)
dim(dtm)[1]
train.Range
test.Range
train.doc
# Generate TAGS - Correct answers for the Train dataset
z <- c(SMS.Data$Tag[train.Range])
z
z==Positive
CM.Names
z <- gsub(Positive,"Positive",z)
z <- gsub(Negative,"Negative",z)
z
# Generate TAGS - Correct answers for the Test dataset
z <- c(SMS.Data$Tag[test.Range]);
sum(z==Positive) # 64 - Number of Positive events ("spam") in the Test Data
sum(z==Negative) # 336 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
z
# 1) KNN Classificationusing package "class" ====
set.seed(0)
prob.test <- knn(train.doc, test.doc, Tags.Train, k = 2, prob=TRUE) # k-number of neighbors considered
### -----------
# Display Classification Results
a <- 1:length(prob.test)
b <- levels(prob.test)[prob.test] # asign your classification Tags (Talk or Sci)
c <- attributes(prob.test)$prob # asign your classification probability values
d <- prob.test==Tags.Test # Logicaly match your classification Tags with the known "Tags"
result <- data.frame(Doc=a,Predict=b,Prob=c, Correct=d) # Tabulate your result
sum(d)/length(Tags.Test) # % Correct Classification (0.86)
a
b
c <- attributes(prob.test)$prob # asign your classification probability values
c
d
result
table(prob.test, Tags.Test)
prob.test
Tags.Test
prob.test
result
Tags.Test
Tags.Train
TP
FP
TN
FN
prob.test == Tags.Test
prob.test
result
spam.classified <- (b == 'Positive')
spam.classified
b
c
ham.classified <- (b == 'Negative')
spam.classified
ham.classified
TP <- sum(spam.classified == TRUE)
FP <- sum(spam.classified == FALSE)
TN <- sum(ham.classified == TRUE)
FN <- sum(ham.classified == FALSE)
confusion.matrix <- data.frame(Spam = c(TP, FN), Ham = c(FP, TN), row.names = c("Spam", "Ham"))
confusion.matrix
TP
FP
TN
FN
spam.classified
b
install.packages("caret", dependencies = c("Depends", "Suggests"))
install.packages('caret', dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages("caret",
repos = "http://cran.r-project.org",
dependencies = c("Depends", "Imports", "Suggests"))
install.packages("caret",
repos = "https://cloud.r-project.org",
dependencies = c("Depends", "Imports", "Suggests"))
install.packages("caret",dependencies = c("Depends", "Imports", "Suggests"))
install.packages("caret",dependencies = c("Depends", "Imports", "Suggests"), repos = 'https://github.com/topepo/caret/')
install.packages("caret", dependencies = c("Depends", "Suggests"))
# Insert your code to find:
# Confusion Matrix
cm <- table(prob.test, Tags.Test)
cm
# Insert your code to find:
# Confusion Matrix
auto_cm <- table(prob.test, Tags.Test)
TP <- auto_cm[1,1]
FP <- auto_cm[2,1]
TN <- auto_cm[1,2]
FN <- auto_cm[2,2]
#precision
precision <- TP/(TP + FP)
precision
#recall
recall <- TP/(TP + FN)
recall
#F score
f.score <- 2*((precision * recall)/(precision + recall))
f.score
#Accuracy
Accuracy <- (TP+TN)/(TP+TN+FP+FN)
Accuracy
TP <- auto_cm[1,1]
FN <- auto_cm[2,1]
FP <- auto_cm[1,2]
TN <- auto_cm[2,2]
#precision
precision <- TP/(TP + FP)
precision
#recall
recall <- TP/(TP + FN)
recall
#F score
f.score <- 2*((precision * recall)/(precision + recall))
f.score
#Accuracy
Accuracy <- (TP+TN)/(TP+TN+FP+FN)
Accuracy
auto_cm
# KNN Classification of SMS Dataset
rm(list=ls()); cat("\014") # clear all
library(tm) # Use this package for Text Mining
load("Data/SMS_DTM.RData") # Load dtm from saved data
dtm <- as.matrix(dtm)
dtm <- dtm[1:1000,] # Subset DTM
# Split the Document-Term Matrix into Train & Test Datasets
library(class) #
# Consider "spam" as Positive and "ham" as Negative
Positive <- "spam";
Negative <- "ham";
CM.Names <- c(Positive,Negative)
DS.Size <- dim(dtm)[1]
Test.Train.Percent <- 0.6 # Split Data into 60% for Training and 40% for Testing
ix.Range <- round(DS.Size*Test.Train.Percent)
train.Range <- seq(from = 1, to = ix.Range, by = 1);
test.Range <- seq(from = (ix.Range+1), to = DS.Size, by = 1)
train.doc <- dtm[train.Range,] # Dataset for which classification is already known
test.doc <- dtm[test.Range,] # Dataset we are trying to classify
# Generate TAGS - Correct answers for the Train dataset
z <- c(SMS.Data$Tag[train.Range])
sum(z==Positive) # 88 - Number of Positive events ("spam") in the Test Data
sum(z==Negative) # 512 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
Tags.Train <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
# Generate TAGS - Correct answers for the Test dataset
z <- c(SMS.Data$Tag[test.Range]);
sum(z==Positive) # 64 - Number of Positive events ("spam") in the Test Data
sum(z==Negative) # 336 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
Tags.Test <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
# 1) KNN Classificationusing package "class" ====
set.seed(0)
prob.test <- knn(train.doc, test.doc, Tags.Train, k = 2, prob=TRUE) # k-number of neighbors considered
### -----------
# Display Classification Results
a <- 1:length(prob.test)
b <- levels(prob.test)[prob.test] # asign your classification Tags (Positive or Negative)
c <- attributes(prob.test)$prob # asign your classification probability values
d <- prob.test==Tags.Test # Logicaly match your classification Tags with the known "Tags"
result <- data.frame(Doc=a,Predict=b,Prob=c, Correct=d) # Tabulate your result
sum(d)/length(Tags.Test) # % Correct Classification (0.86)
# Insert your code to find:
# Confusion Matrix
auto_cm <- table(prob.test, Tags.Test)
TP <- auto_cm[1,1]
FP <- auto_cm[1,2]
FN <- auto_cm[2,1]
TN <- auto_cm[2,2]
#precision
precision <- TP/(TP + FP)
precision
#recall
recall <- TP/(TP + FN)
recall
#F score
f.score <- 2*((precision * recall)/(precision + recall))
f.score
#Accuracy
Accuracy <- (TP+TN)/(TP+TN+FP+FN)
Accuracy
# KNN Classification of SMS Dataset
rm(list=ls()); cat("\014") # clear all
library(tm) # Use this package for Text Mining
load("Data/SMS_DTM.RData") # Load dtm from saved data
dtm <- as.matrix(dtm)
dtm <- dtm[1:1000,] # Subset DTM
# Split the Document-Term Matrix into Train & Test Datasets
library(class) #
# Consider "spam" as Positive and "ham" as Negative
Positive <- "spam";
Negative <- "ham";
CM.Names <- c(Positive,Negative)
DS.Size <- dim(dtm)[1]
Test.Train.Percent <- 0.6 # Split Data into 60% for Training and 40% for Testing
ix.Range <- round(DS.Size*Test.Train.Percent)
train.Range <- seq(from = 1, to = ix.Range, by = 1);
test.Range <- seq(from = (ix.Range+1), to = DS.Size, by = 1)
train.doc <- dtm[train.Range,] # Dataset for which classification is already known
test.doc <- dtm[test.Range,] # Dataset we are trying to classify
# Generate TAGS - Correct answers for the Train dataset
z <- c(SMS.Data$Tag[train.Range])
sum(z==Positive) # 88 - Number of Positive events ("spam") in the Test Data
sum(z==Negative) # 512 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
Tags.Train <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
# Generate TAGS - Correct answers for the Test dataset
z <- c(SMS.Data$Tag[test.Range]);
sum(z==Positive) # 64 - Number of Positive events ("spam") in the Test Data
sum(z==Negative) # 336 - Number of Negative events ("ham") in the Test Data
z <- gsub(Positive,"Positive",z); z <- gsub(Negative,"Negative",z) # Replace Tags with
Tags.Test <- factor(z, levels = c("Positive","Negative")) # kNN expects Tags to be Factors data type
# 1) KNN Classificationusing package "class" ====
set.seed(0)
prob.test <- knn(train.doc, test.doc, Tags.Train, k = 2, prob=TRUE) # k-number of neighbors considered
### -----------
# Display Classification Results
a <- 1:length(prob.test)
b <- levels(prob.test)[prob.test] # asign your classification Tags (Positive or Negative)
c <- attributes(prob.test)$prob # asign your classification probability values
d <- prob.test==Tags.Test # Logicaly match your classification Tags with the known "Tags"
result <- data.frame(Doc=a,Predict=b,Prob=c, Correct=d) # Tabulate your result
sum(d)/length(Tags.Test) # % Correct Classification (0.86)
# Insert your code to find:
# Confusion Matrix
auto_cm <- table(prob.test, Tags.Test)
TP <- auto_cm[1,1]
FP <- auto_cm[1,2]
FN <- auto_cm[2,1]
TN <- auto_cm[2,2]
#precision
precision <- TP/(TP + FP)
precision
#recall
recall <- TP/(TP + FN)
recall
#F score
f.score <- 2*((precision * recall)/(precision + recall))
f.score
##Accuracy
Accuracy <- (TP+TN)/(TP+TN+FP+FN)
Accuracy
library(caret)
set.seed(0)
#prepare data by addiing to DTM a column of document's class
train.doc1 <- as.data.frame(train.doc, stringAsFactors=False);
train.doc1$doc.class <- as.character(Tags.Train)
test.doc1 <- as.data.frame(test.doc, stringAsFactors=False);
test.doc1 <- as.character(Tags.Test)
ctrl <- trainControl(method = "repearedcv", number = 10, repeats = 3)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
Knn.Train <- train(doc.class ~ ., data = train.doc1, method = "knn", trControl = ctrl)
Knn.Predict <- predict(Knn.Train, newdata = test.doc1)
CM.Knn <- confusionMatrix(Knn.Predict, test.doc1$doc.class)
FScore.Knn <- CM.Knn$byClass[7]
print(FScore.Knn)
FScore.Knn
Knn.Predict <- predict(Knn.Train, newdata = test.doc1)
Knn.Predict <- predict(Knn.Train, newdata = test.doc1)
Knn.Predict
Knn.Train
Knn.Train
Knn.Predict <- predict(Knn.Train, newdata = test.doc1)
predict(Knn.Train, newdata = test.doc1)
CM.Knn <- confusionMatrix(Knn.Predict, test.doc1$doc.class)
#prepare data by addiing to DTM a column of document's class
train.doc1 <- as.data.frame(train.doc, stringAsFactors=False);
train.doc1$doc.class <- as.character(Tags.Train)
test.doc1 <- as.data.frame(test.doc, stringAsFactors=False);
test.doc1 <- as.character(Tags.Test)
test.doc1
Knn.Predict <- predict(Knn.Train, newdata = test.doc1)
Knn.Predict <- predict(Knn.Train, newdata = test.doc1, type = 'class')
Knn.Predict <- predict(Knn.Train, newdata = test.doc1)
test.doc1$doc.class <- as.character(Tags.Test)
#prepare data by addiing to DTM a column of document's class
train.doc1 <- as.data.frame(train.doc, stringAsFactors=False);
train.doc1$doc.class <- as.character(Tags.Train)
test.doc1 <- as.data.frame(test.doc, stringAsFactors=False);
test.doc1$doc.class <- as.character(Tags.Test)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
Knn.Train <- train(doc.class ~ ., data = train.doc1, method = "knn", trControl = ctrl)
Knn.Predict <- predict(Knn.Train, newdata = test.doc1)
CM.Knn <- confusionMatrix(Knn.Predict, test.doc1$doc.class)
test.doc1$doc.class
Knn.Predict
CM.Knn <- confusionMatrix(Knn.Predict, test.doc1$doc.class)
Knn.Predict
test.doc1$doc.class
CM.Knn <- confusionMatrix(Knn.Predict, test.doc1$doc.class)
test.doc0001$doc.class <- as.factor(Tags.Test)
as.factor(Tags.Test)
test.doc0001 <- as.factor(Tags.Test)
CM.Knn <- confusionMatrix(Knn.Predict, test.doc0001)# test.doc1$doc.class)
CM.Knn
FScore.Knn <- CM.Knn$byClass[7]
FScore.Knn
print(FScore.Knn)
knitr::kable(Knn.Train$results, digits = 6, format.args = list(big.mark = ","))
Knn.k <- Knn.Train$bestTune$k
Accuracy.Knn <- Knn.Train$results$Accuracy[Knn.Train$results$k == Knn.k]
Accuracy.Knn
#3 SVM classification
set.seed(100)
SVM.Train <- train(doc.class ~., data = train.doc1, method = "svmRadial", trControl = ctrl)
# KNN Classification of SMS Dataset
rm(list=ls()); cat("\014") # clear all
My.Name <- "Saroj Lamichhane"
My.Name
## Q1: (5 points). Assign your First name Space Last name to an R object called "My.Name"
My.Name <- "Saroj Lamichhane"
## Q2: (10 points). Using "dbinom()" plot Binomial probability distribution with the following arguments:
## number of trials = 150, and probability of success for a single trial = 0.33.
trialNum <- 150
prob <- 0.33
trial <- seq(from=0, to=trialNum, by=1)
freq <- dbinom(trial, size=trialNum, prob=prob)
plot(trial,freq)
## Q2: (10 points). Using "dbinom()" plot Binomial probability distribution with the following arguments:
## number of trials = 150, and probability of success for a single trial = 0.33.
trialNum <- 150
prob <- 0.33
trial <- seq(from = 0, to = trialNum, by = 1)
freq <- dbinom(trial, size = trialNum, prob = prob)
plot(trial, freq, main = "Binomial Probability Distribution")
cor(mtcars)
## a. Write a line of code to find the correlation of Mpg & Hp.
cor(mtcars$mpg, mtcars$hp)
## b. Use "cor.test()" of Mpg & Hp to find the p-value.
cor.test(mtcars$mpg, mtcars$hp)
# b. Use "cor.test()" of Mpg & Hp to find the p-value.
cor.test(mtcars$mpg, mtcars$hp)
cor.test(mtcars$mpg, mtcars$hp)$p-value
a<- cor.test(mtcars$mpg, mtcars$hp)
cor.test(mtcars$mpg, mtcars$hp)$p.value
cor.test(mtcars$mpg, mtcars$hp)$p.value
Y <- mtcars$mpg
X <- factor(mtcars$cyl)
aov(Y~X)
# b. To get the p-value, you would need to execute the following code
model <- aov(Y~X)
summary(model)
##Q5: (10 points). Repeat the same as Q4, but for Gross horsepower (mtcars$hp) and Weight (1000 lbs)
# a. Y <- mtcars$hp
Y <- mtcars$hp
# b. X <- factor(mtcars$wt)
X <- factor(mtcars$wt)
model <- aov(Y~X)
summary(model)
mtcars$wt
mtcars
?mtcars
Y <- mtcars$mpg
X <- factor(mtcars$cyl)
aov(Y~X)
#Quiz
rm(list=ls()); cat("\014") # clear all
# Q1: (5 points). Assign your First name Space Last name to an R object called "My.Name"
My.Name <- "Saroj Lamichhane"
# Q2: (10 points). Using "dbinom()" plot Binomial probability distribution with the following arguments:
# number of trials = 150, and probability of success for a single trial = 0.33.
trialNum <- 150
prob <- 0.33
trial <- seq(from = 0, to = trialNum, by = 1)
freq <- dbinom(trial, size = trialNum, prob = prob)
plot(trial, freq, main = "Binomial Probability Distribution")
?mtcars
cor(mtcars)
# a.Write a line of code to find the correlation of Mpg & Hp.
cor(mtcars$mpg, mtcars$hp)
# b.Use "cor.test()" of Mpg & Hp to find the p-value.
cor.test(mtcars$mpg, mtcars$hp)
cor.test(mtcars$mpg, mtcars$hp)$p.value
Y <- mtcars$mpg
X <- factor(mtcars$cyl)
aov(Y~X)
# b. To get the p-value, you would need to execute the following code
model <- aov(Y~X)
summary(model)
#Q5: (10 points). Repeat the same as Q4, but for Gross horsepower (mtcars$hp) and Weight (1000 lbs)
# a. Y <- mtcars$hp
Y <- mtcars$hp
# b. X <- factor(mtcars$wt)
X <- factor(mtcars$wt)
model <- aov(Y~X)
summary(model)
# Answer: The null hypotesis is kept(fail to reject) because
